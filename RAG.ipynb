{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import openai\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex, \n",
    "    SimpleDirectoryReader, \n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found, Loading the index...\n"
     ]
    }
   ],
   "source": [
    "PERSIST_DIR = \"./storage\"\n",
    "if not os.path.exists(PERSIST_DIR):  # not found\n",
    "    print(\"Not Found, Creating the index...\")\n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        llm=OpenAI(model=\"gpt-4\", temperature=0.1))\n",
    "    \n",
    "    documents = SimpleDirectoryReader(\"./documents/\").load_data()\n",
    "\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents, service_context=service_context, show_progress=True)\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "    \n",
    "else:  # found\n",
    "    print(\"Found, Loading the index...\")\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_engine = index.as_chat_engine(\n",
    "#     similarity_top_k=4, response_mode=\"compact\")  # Chat\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=4, response_mode=\"compact\")  # QA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instabug prioritizes data privacy and security, ensuring that your data remains solely yours. They do not share, monetize, or access your data at any point. Additionally, Instabug complies with major privacy laws and offers enterprise-grade security measures to safeguard the privacy and security of your app and its users. With customizable auto-masking of user data and granular manual customization options, you have complete control over the data collected from your users.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"does instabug protect my data?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import sys\n",
    "\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
